{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T06:01:08.782800Z",
     "start_time": "2019-09-08T06:01:06.285370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fio/anaconda3/envs/cpu/lib/python3.7/site-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n",
      "Serving on http://0.0.0.0:12350\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#匯入模型\n",
    "model = keras.models.load_model(\"./0903_size32.h5\")\n",
    "model.trainable = False\n",
    "model.compile(\n",
    "    # Technical note: when using embedding layers, I highly recommend using one of the optimizers\n",
    "    # found  in tf.train: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    # Passing in a string like 'adam' or 'SGD' will load one of keras's optimizers (found under \n",
    "    # tf.keras.optimizers). They seem to be much slower on problems like this, because they\n",
    "    # don't efficiently handle sparse gradient updates.\n",
    "    tf.train.AdamOptimizer(0.005),\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "temp = model.predict([np.array([3]).reshape(-1,1), np.array([3]).reshape(-1,1)])\n",
    "del temp\n",
    "\n",
    "\n",
    "embedd_movies = model.get_layer(name = \"Embedd_movies\")\n",
    "\n",
    "(w,) = embedd_movies.get_weights()\n",
    "movie_embedding_size = w.shape[1]\n",
    "\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "\n",
    "#匯入資料\n",
    "import pandas as pd\n",
    "movies = pd.read_csv(\"/home/fio/Python/movielens_20m/Data/movie_pro.csv\")\n",
    "movies = movies[movies.n_rating>1000]\n",
    "moviename = movies.title\n",
    "\n",
    "movies = movies[movies.n_rating>1000]\n",
    "\n",
    "movie_id_list = np.array(movies.movieId)\n",
    "movie_id_len = len(movie_id_list)\n",
    "title_list = movies['title'].copy()\n",
    "title_list_total = pd.DataFrame(data = title_list)\n",
    "\n",
    "\n",
    "#get similar\n",
    "kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\n",
    "kv.add(\n",
    "    movies['title'].values,\n",
    "    w[movies.movieId]\n",
    ")\n",
    "\n",
    "#kv.most_similar(name)\n",
    "\n",
    "\n",
    "\n",
    "#定義API\n",
    "\n",
    "from flask import Flask, request, abort\n",
    "app = Flask(__name__)\n",
    "\n",
    "from waitress import serve\n",
    "\n",
    "@app.route(\"/callback\")\n",
    "def callback():\n",
    "    return 'OK'\n",
    "\n",
    "@app.route(\"/api/gs/<string:name>\")\n",
    "def similar_first(name):\n",
    "    try: name = np.array(moviename[moviename.str.contains(name.title())])[0]\n",
    "    except IndexError:return \"Movie not found.\"\n",
    "    #print(\"Most similar with %s:\"%(name))\n",
    "    string = 'According to the rates by audience.<br>The movie %s is more similar to:<br><br>'%(name)\n",
    "    try:\n",
    "        for i,j in kv.most_similar(name):\n",
    "            string+=\"%s, %f <br/>\"%(i,j)\n",
    "    except KeyError: \n",
    "        print(\" Error Key : %s\"%(name))\n",
    "        return \"Key Error, Try another word.\"\n",
    "    return string\n",
    "\n",
    "\n",
    "@app.route(\"/api/rm/<int:userId>\")\n",
    "def recommand(userId):\n",
    "    num = 5\n",
    "    ids = [userId]*movie_id_len\n",
    "    result = model.predict([ids, movie_id_list])\n",
    "    title_list = title_list_total.copy()\n",
    "    title_list['predict'] = result+3.7 \n",
    "    title_list = title_list.sort_values(\"predict\", ascending=False).head(num)\n",
    "    rating_list = list(title_list.predict)\n",
    "    title_list = list(title_list.title)\n",
    "    string = (\"User %d will most likely to like:<br/>\"%(ids[0]))\n",
    "    for i in range(len(title_list)):\n",
    "        string+=(\" %.1f    %s <br>\"%(rating_list[i], title_list[i]))\n",
    "    return string\n",
    "\n",
    "@app.route(\"/api/sf/<string:inputs>\")\n",
    "def predict_s(inputs):\n",
    "    user = inputs.split(\"<>\")[0]\n",
    "    movie_name = inputs.split(\"<>\")[1:]\n",
    "    print(inputs)\n",
    "    user = [user] * len(movie_name)\n",
    "    movie_ids = []\n",
    "    movie_name_list = []\n",
    "    for i in range(len(movie_name)):\n",
    "        try: \n",
    "            temp_df = movies[movies.title.str.contains(movie_name[i].title())].head(1)\n",
    "        except IndexError:\n",
    "            return \"Movie not found.\"\n",
    "        try: movie_name_list.append(str(temp_df.title)[3:].replace(\"    \",\"\").replace(\"\\nName: title, dtype: object\",\"\"))\n",
    "        except TypeError:\n",
    "            return \"Movie not found.\"\n",
    "        try: movie_ids.append(int(temp_df.movieId))\n",
    "        except TypeError:\n",
    "            return \"Movie not found.\"\n",
    "    #print(movie_name)\n",
    "    result = model.predict([user, movie_ids]) + 3.7\n",
    "    string = \"User %d to below movies rating prediction is:<br>\"%(int(user[0]))\n",
    "    for i in range(len(movie_name_list)):\n",
    "        string += \"%.2f - %s<br>\"%(result[i], movie_name_list[i])\n",
    "    return string\n",
    "    \n",
    "    \n",
    "#啟動server\n",
    "import sys \n",
    "print(sys.version)\n",
    "if __name__ == \"__main__\":\n",
    "    serve(app, host = '0.0.0.0', port = 12347)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://114.32.20.219:12347/api/gs/Thor\n",
    "\n",
    "http://114.32.20.219:12347/api/rm/1\n",
    "\n",
    "http://114.32.20.219:12347/api/sf/1%3C%3EIron%20Man%3C%3EToy%20Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
