{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機器學習模型訓練與 API 部署\n",
    "這是我使用keras訓練神經網路的程式碼。<br>\n",
    "這個模型是關於商品推薦的模型，會根據顧客對電影的評價，推薦給顧客他可能會喜歡的電影<br>\n",
    "使用的機器學習方法是Embedding與NN神經網路。<br>\n",
    "**對應於均一，可以推薦適合的課程給學生，達到客製化推薦的目的。**<br>\n",
    "Flask套件部署我的神經網路模型至網路上的程式碼<br>\n",
    "部署後的資料，會使用Json的格式傳送到前端，再由前端工程師將其視覺化。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:47.743230Z",
     "start_time": "2019-09-13T14:07:41.615112Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./Data/0913_all_movie_rating\").drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:47.783941Z",
     "start_time": "2019-09-13T14:07:47.774788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>y</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating    y  n_ratings    title\n",
       "0       1        2     3.5 -0.2      22243  Jumanji\n",
       "1       5        2     3.0 -0.7      22243  Jumanji\n",
       "2      13        2     3.0 -0.7      22243  Jumanji\n",
       "3      29        2     3.0 -0.7      22243  Jumanji\n",
       "4      34        2     3.0 -0.7      22243  Jumanji"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:47.816974Z",
     "start_time": "2019-09-13T14:07:47.814827Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def telegram_bot_sendtext(bot_message):\n",
    "    \n",
    "    bot_token = '661544421:AAHuZSMukZmFlhU-npE23CowogP375a0au4'\n",
    "    bot_chatID = '-225157366'\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n",
    "\n",
    "    response = requests.get(send_text)\n",
    "\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:51.672153Z",
     "start_time": "2019-09-13T14:07:51.670336Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:53.637848Z",
     "start_time": "2019-09-13T14:07:53.632043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>y</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>22243</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating    y  n_ratings    title\n",
       "0       1        2     3.5 -0.2      22243  Jumanji\n",
       "1       5        2     3.0 -0.7      22243  Jumanji\n",
       "2      13        2     3.0 -0.7      22243  Jumanji\n",
       "3      29        2     3.0 -0.7      22243  Jumanji\n",
       "4      34        2     3.0 -0.7      22243  Jumanji"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:55.518695Z",
     "start_time": "2019-09-13T14:07:55.455436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedd_user (Embedding)         (None, 1, 32)        4432096     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Embedd_movies (Embedding)       (None, 1, 32)        4200704     movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_user (Dropout)          (None, 1, 32)        0           Embedd_user[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_movie (Dropout)         (None, 1, 32)        0           Embedd_movies[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           Dropout_user[0][0]               \n",
      "                                                                 Dropout_movie[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 8,632,800\n",
      "Trainable params: 8,632,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Emb_size = 32\n",
    "movie_r12n = keras.regularizers.l2(1e-6)\n",
    "user_r12n = keras.regularizers.l2(1e-7)\n",
    "movie_r12n = None\n",
    "user_r12n = None\n",
    "\n",
    "user_input = keras.Input(shape = (1,), name = \"user_id\")\n",
    "movie_input = keras.Input(shape = (1,), name = \"movie_id\")\n",
    "mean_rate = keras.Input(shape = (1,), name = \"mean_rate\")\n",
    "Embedd_user = keras.layers.Embedding(df.userId.max()+10,Emb_size, name=\"Embedd_user\",\n",
    "                                     input_length=1, embeddings_regularizer= movie_r12n)(user_input)\n",
    "Embedd_movies = keras.layers.Embedding(df.movieId.max()+10,Emb_size, name=\"Embedd_movies\", \n",
    "                                       input_length=1, embeddings_regularizer= user_r12n)(movie_input)\n",
    "user_dropout = keras.layers.Dropout(0.3, name=\"Dropout_user\")(Embedd_user)\n",
    "movie_dropout = keras.layers.Dropout(0.3, name=\"Dropout_movie\")(Embedd_movies)\n",
    "Dot = keras.layers.Dot(2)([user_dropout, movie_dropout])\n",
    "Flatten = keras.layers.Flatten()(Dot)\n",
    "model = keras.Model(\n",
    "    inputs = [user_input, movie_input],\n",
    "    outputs = Flatten\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:07:56.761038Z",
     "start_time": "2019-09-13T14:07:56.757939Z"
    }
   },
   "outputs": [],
   "source": [
    "u_train = df.userId\n",
    "m_train = df.movieId\n",
    "y_train = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:02:58.063141Z",
     "start_time": "2019-09-13T14:02:54.858064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split to:\n",
      "train: 14000184\n",
      "test:  6000079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "u_train, u_test, m_train, m_test, y_train, y_test = train_test_split(df.userId, df.movieId, df.y,\n",
    "                                                                     test_size= 0.3,\n",
    "                                                                    random_state = 878)\n",
    "print(\"split to:\\ntrain: %d\\ntest:  %d\"%(u_train.shape[0], u_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:08:00.872229Z",
     "start_time": "2019-09-13T14:08:00.870333Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "'''import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import keras\n",
    "run_metadata = tf.RunMetadata()\n",
    "keras.backend.set_session(\n",
    "    tf_debug.TensorBoardDebugWrapperSession(tf.Session(), \"fio:6007\"))'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:08:01.880372Z",
     "start_time": "2019-09-13T14:08:01.878343Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "from time import time as currentTime\n",
    "import tensorflow as tf\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(currentTime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:08:04.981860Z",
     "start_time": "2019-09-13T14:08:04.966600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedd_user (Embedding)         (None, 1, 32)        4432096     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Embedd_movies (Embedding)       (None, 1, 32)        4200704     movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_user (Dropout)          (None, 1, 32)        0           Embedd_user[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_movie (Dropout)         (None, 1, 32)        0           Embedd_movies[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           Dropout_user[0][0]               \n",
      "                                                                 Dropout_movie[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 8,632,800\n",
      "Trainable params: 8,632,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    # Technical note: when using embedding layers, I highly recommend using one of the optimizers\n",
    "    # found  in tf.train: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    # Passing in a string like 'adam' or 'SGD' will load one of keras's optimizers (found under \n",
    "    # tf.keras.optimizers). They seem to be much slower on problems like this, because they\n",
    "    # don't efficiently handle sparse gradient updates.\n",
    "    tf.train.AdamOptimizer(0.005),\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:14:01.663147Z",
     "start_time": "2019-09-13T14:08:25.853742Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000263 samples, validate on 20000263 samples\n",
      "Epoch 1/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.9393 - mean_absolute_error: 0.7503\n",
      "Epoch 2/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.7209 - mean_absolute_error: 0.6507\n",
      "Epoch 3/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6920 - mean_absolute_error: 0.6378\n",
      "Epoch 4/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6779 - mean_absolute_error: 0.6317\n",
      "Epoch 5/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6687 - mean_absolute_error: 0.6275 - val_loss: 0.5833 - val_mean_absolute_error: 0.5849\n",
      "Epoch 6/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6620 - mean_absolute_error: 0.6246\n",
      "Epoch 7/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6570 - mean_absolute_error: 0.6224\n",
      "Epoch 8/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6532 - mean_absolute_error: 0.6207\n",
      "Epoch 9/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6496 - mean_absolute_error: 0.6190\n",
      "Epoch 10/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6471 - mean_absolute_error: 0.6179 - val_loss: 0.5506 - val_mean_absolute_error: 0.5688\n",
      "Epoch 11/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6451 - mean_absolute_error: 0.6170\n",
      "Epoch 12/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6434 - mean_absolute_error: 0.6162\n",
      "Epoch 13/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6419 - mean_absolute_error: 0.6155\n",
      "Epoch 14/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6404 - mean_absolute_error: 0.6148\n",
      "Epoch 15/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6392 - mean_absolute_error: 0.6142 - val_loss: 0.5369 - val_mean_absolute_error: 0.5619\n",
      "Epoch 16/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6382 - mean_absolute_error: 0.6137\n",
      "Epoch 17/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6376 - mean_absolute_error: 0.6134\n",
      "Epoch 18/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6366 - mean_absolute_error: 0.6130\n",
      "Epoch 19/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6358 - mean_absolute_error: 0.6126\n",
      "Epoch 20/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6350 - mean_absolute_error: 0.6122 - val_loss: 0.5296 - val_mean_absolute_error: 0.5581\n",
      "Epoch 21/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6345 - mean_absolute_error: 0.6120\n",
      "Epoch 22/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6340 - mean_absolute_error: 0.6118\n",
      "Epoch 23/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6333 - mean_absolute_error: 0.6114\n",
      "Epoch 24/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6330 - mean_absolute_error: 0.6112\n",
      "Epoch 25/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6325 - mean_absolute_error: 0.6111 - val_loss: 0.5252 - val_mean_absolute_error: 0.5559\n",
      "Epoch 26/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6322 - mean_absolute_error: 0.6108\n",
      "Epoch 27/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6318 - mean_absolute_error: 0.6107\n",
      "Epoch 28/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6314 - mean_absolute_error: 0.6104\n",
      "Epoch 29/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6311 - mean_absolute_error: 0.6104\n",
      "Epoch 30/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6307 - mean_absolute_error: 0.6102 - val_loss: 0.5221 - val_mean_absolute_error: 0.5544\n",
      "Epoch 31/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6307 - mean_absolute_error: 0.6103\n",
      "Epoch 32/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6302 - mean_absolute_error: 0.6099\n",
      "Epoch 33/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6299 - mean_absolute_error: 0.6098\n",
      "Epoch 34/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6298 - mean_absolute_error: 0.6097\n",
      "Epoch 35/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6295 - mean_absolute_error: 0.6095 - val_loss: 0.5197 - val_mean_absolute_error: 0.5530\n",
      "Epoch 36/40\n",
      "20000263/20000263 [==============================] - 7s 0us/step - loss: 0.6295 - mean_absolute_error: 0.6095\n",
      "Epoch 37/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6292 - mean_absolute_error: 0.6094\n",
      "Epoch 38/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6291 - mean_absolute_error: 0.6094\n",
      "Epoch 39/40\n",
      "20000263/20000263 [==============================] - 8s 0us/step - loss: 0.6289 - mean_absolute_error: 0.6092\n",
      "Epoch 40/40\n",
      "20000263/20000263 [==============================] - 12s 1us/step - loss: 0.6287 - mean_absolute_error: 0.6091 - val_loss: 0.5181 - val_mean_absolute_error: 0.5523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit([u_train, m_train], y_train, batch_size= 100000, epochs=40,\n",
    "    verbose=1, callbacks = [tensorboard], validation_data=[[u_train, m_train], y_train],\n",
    "                    validation_freq= 5)\n",
    " #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:05:46.704563Z",
     "start_time": "2019-09-13T14:05:07.224Z"
    }
   },
   "outputs": [],
   "source": [
    "result = model.predict([u_train, m_train]).reshape(-1) - y_train\n",
    "train_mean=abs(result).mean()\n",
    "train_std = result.std()\n",
    "del result\n",
    "result = model.predict([u_test, m_test]).reshape(-1) - y_test\n",
    "test_mean = abs(result).mean()\n",
    "test_std = result.std()\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:05:46.706292Z",
     "start_time": "2019-09-13T14:05:15.280Z"
    }
   },
   "outputs": [],
   "source": [
    "result = \"結果出來了，訓練結果訓練資料:\\nabs(loss).mean() = \"+ str(train_mean) + \" \\n標準差 = \" + str(train_std)+\"\\n\\n測試資料:\\nabs(loss).mean() = \"+ str(test_mean) + \" \\n標準差 = \" + str(test_std)\n",
    "\n",
    "telegram_bot_sendtext(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "#匯入模型\n",
    "model = keras.models.load_model(\"./0903_size32.h5\")\n",
    "model.trainable = False\n",
    "model.compile(\n",
    "    # Technical note: when using embedding layers, I highly recommend using one of the optimizers\n",
    "    # found  in tf.train: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "    # Passing in a string like 'adam' or 'SGD' will load one of keras's optimizers (found under \n",
    "    # tf.keras.optimizers). They seem to be much slower on problems like this, because they\n",
    "    # don't efficiently handle sparse gradient updates.\n",
    "    tf.train.AdamOptimizer(0.005),\n",
    "    loss='MSE',\n",
    "    metrics=['MAE'],\n",
    ")\n",
    "#model.summary()\n",
    "temp = model.predict([np.array([3]).reshape(-1,1), np.array([3]).reshape(-1,1)])\n",
    "del temp\n",
    "\n",
    "\n",
    "embedd_movies = model.get_layer(name = \"Embedd_movies\")\n",
    "\n",
    "(w,) = embedd_movies.get_weights()\n",
    "movie_embedding_size = w.shape[1]\n",
    "\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "\n",
    "#匯入資料\n",
    "import pandas as pd\n",
    "movies = pd.read_csv(\"/home/fio/Python/movielens_20m/Data/movie_pro.csv\")\n",
    "movies = movies[movies.n_rating>1000]\n",
    "\n",
    "def munge_title(title):\n",
    "    l = title.rfind('(') + 1\n",
    "    year = int(title[l:l+4])\n",
    "    i = title.rfind(' (')\n",
    "    if i != -1:\n",
    "        title = title[:i]\n",
    "    for suff_word in ['The', 'A', 'An']:\n",
    "        suffix = ', {}'.format(suff_word)\n",
    "        if title.endswith(suffix):\n",
    "            title = suff_word + ' ' + title[:-len(suffix)]\n",
    "    return title+' ('+str(year)+')'\n",
    "\n",
    "movies['title'] = movies['title'].map(munge_title)\n",
    "\n",
    "moviename = movies.title\n",
    "\n",
    "movies = movies[movies.n_rating>1000]\n",
    "\n",
    "movie_id_list = np.array(movies.movieId)\n",
    "movie_id_len = len(movie_id_list)\n",
    "title_list = movies['title'].copy()\n",
    "title_list_total = pd.DataFrame(data = title_list)\n",
    "title_list_total['movieId'] = np.array(movies.movieId)\n",
    "\n",
    "#get similar\n",
    "kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\n",
    "kv.add(\n",
    "    movies['title'].values,\n",
    "    w[movies.movieId]\n",
    ")\n",
    "\n",
    "#kv.most_similar(name)\n",
    "\n",
    "\n",
    "\n",
    "#定義API\n",
    "\n",
    "from flask import Flask, request, abort\n",
    "from flask_cors import CORS\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "from waitress import serve\n",
    "\n",
    "@app.route(\"/callback\")\n",
    "def callback():\n",
    "    return 'OK'\n",
    "\n",
    "@app.route(\"/api/gs/<string:name>\")\n",
    "def similar_first(name):\n",
    "    try: name = np.array(moviename[moviename.str.contains(name)])[0]\n",
    "    except IndexError:return \"Movie not found.\"\n",
    "    #print(\"Most similar with %s:\"%(name))\n",
    "    string = 'According to the rates by audience.<br>The movie %s is more similar to:<br><br>'%(name)\n",
    "    try:\n",
    "        for i,j in kv.most_similar(name):\n",
    "            string+=\"%s, %f <br/>\"%(i,j)\n",
    "    except KeyError: \n",
    "        print(\" Error Key : %s\"%(name))\n",
    "        return \"Key Error, Try another word.\"\n",
    "    return string\n",
    "\n",
    "@app.route(\"/api/gsj_title/<string:title>\")\n",
    "def similar_title_json(title):\n",
    "    nums = 5\n",
    "    movie_title = np.array(moviename[moviename.str.contains(title)])[0]\n",
    "    movieid = list(movies[movies.title == movie_title].movieId)[0]\n",
    "    result = kv.most_similar(movie_title)\n",
    "    target_movie_title_list = []\n",
    "    movie_similar_rate = []\n",
    "    target_movie_id_list = []\n",
    "    for i in range(nums):\n",
    "        target = result[i]\n",
    "        target_movie_title_list.append(target[0])\n",
    "        movie_similar_rate.append(target[1])\n",
    "    out = {\n",
    "        \"input_movieId\": movieid,\n",
    "        \"input_movie_title\" : str(movie_title),\n",
    "        \"similar_movie_title_list\" : target_movie_title_list,\n",
    "        \"similar_movie_similar_rate\" : movie_similar_rate\n",
    "    }\n",
    "    return json.dumps(out)\n",
    "\n",
    "@app.route(\"/api/gsj_2_title/<string:title>\")\n",
    "def similar_2_title_json(title):\n",
    "    title = title.split(\"<>\")\n",
    "    nums = 5\n",
    "    movie_title = []\n",
    "    movieid = []\n",
    "    for i in title:\n",
    "        movie_title.append(np.array(moviename[moviename.str.contains(i)])[0])\n",
    "        movieid.append(list(movies[movies.title == movie_title[-1]].movieId)[0])\n",
    "    result = kv.most_similar(movie_title)\n",
    "    target_movie_title_list = []\n",
    "    movie_similar_rate = []\n",
    "    target_movie_id_list = []\n",
    "    for i in range(nums):\n",
    "        target = result[i]\n",
    "        target_movie_title_list.append(target[0])\n",
    "        movie_similar_rate.append(target[1])\n",
    "    out = {\n",
    "        \"input_movieId\": movieid,\n",
    "        \"input_movie_title\" : str(movie_title),\n",
    "        \"similar_movie_title_list\" : target_movie_title_list,\n",
    "        \"similar_movie_similar_rate\" : movie_similar_rate\n",
    "    }\n",
    "    return json.dumps(out)\n",
    "\n",
    "\n",
    "@app.route(\"/api/gsj_id/<int:movieid>\")\n",
    "def similar_id_json(movieid):\n",
    "    nums = 5\n",
    "    movie_title = title_list_total[title_list_total.movieId == movieid].title\n",
    "    result = kv.most_similar(movie_title)\n",
    "    target_movie_title_list = []\n",
    "    movie_similar_rate = []\n",
    "    target_movie_id_list = []\n",
    "    for i in range(nums):\n",
    "        target = result[i]\n",
    "        target_movie_title_list.append(target[0])\n",
    "        movie_similar_rate.append(target[1])\n",
    "    out = {\n",
    "        \"input_movieId\": movieid,\n",
    "        \"input_movie_title\" : str(list(movie_title)[0]),\n",
    "        \"similar_movie_title_list\" : target_movie_title_list,\n",
    "        \"similar_movie_similar_rate\" : movie_similar_rate\n",
    "    }\n",
    "    return json.dumps(out)\n",
    "\n",
    "@app.route(\"/api/rm/<int:userId>\")\n",
    "def recommand(userId):\n",
    "    num = 5\n",
    "    ids = [userId]*movie_id_len\n",
    "    result = model.predict([ids, movie_id_list])\n",
    "    title_list = title_list_total.copy()\n",
    "    title_list['predict'] = result+3.7 \n",
    "    title_list = title_list.sort_values(\"predict\", ascending=False).head(num)\n",
    "    rating_list = list(title_list.predict)\n",
    "    title_list = list(title_list.title)\n",
    "    string = (\"User %d will most likely to like:<br/>\"%(ids[0]))\n",
    "    for i in range(len(title_list)):\n",
    "        string+=(\" %.1f    %s <br>\"%(rating_list[i], title_list[i]))\n",
    "    return string\n",
    "\n",
    "@app.route(\"/api/rmj/<int:userId>\")\n",
    "def recommand_json(userId):\n",
    "    num = 5\n",
    "    ids = [userId]*movie_id_len\n",
    "    result = model.predict([ids, movie_id_list])\n",
    "    title_list = title_list_total.copy()\n",
    "    title_list['predict'] = result+3.7 \n",
    "    title_list = title_list.sort_values(\"predict\", ascending=False).head(num)\n",
    "    title_list.head()\n",
    "    rating_list = list(title_list.predict)\n",
    "    movie_title_list = list(title_list.title)\n",
    "    id_list = list(title_list.movieId)\n",
    "    out_title_list = []\n",
    "    out_movieId_list = []\n",
    "    out_movie_rating = []\n",
    "    for i in range(len(movie_title_list)):\n",
    "        out_title_list.append(movie_title_list[i])\n",
    "        out_movieId_list.append(id_list[i])\n",
    "        out_movie_rating.append(rating_list[i])\n",
    "    out = {'error_msg':\"\",\n",
    "           'userId': ids[0],\n",
    "           'recommend_movie_id': out_movieId_list,\n",
    "           'recommend_movie_title': out_title_list,\n",
    "           'rating_sort': out_movie_rating}\n",
    "    return json.dumps(out)\n",
    "\n",
    "@app.route(\"/api/sf/<string:inputs>\")\n",
    "def predict_s(inputs):\n",
    "    user = inputs.split(\"<>\")[0]\n",
    "    movie_name = inputs.split(\"<>\")[1:]\n",
    "    print(inputs)\n",
    "    user = [user] * len(movie_name)\n",
    "    movie_ids = []\n",
    "    movie_name_list = []\n",
    "    for i in range(len(movie_name)):\n",
    "        try: \n",
    "            temp_df = movies[movies.title.str.contains(movie_name[i])].head(1)\n",
    "        except IndexError:\n",
    "            return \"Movie not found.\"\n",
    "        try: movie_name_list.append(str(temp_df.title)[3:].replace(\"    \",\"\").replace(\"\\nName: title, dtype: object\",\"\"))\n",
    "        except TypeError:\n",
    "            return \"Movie not found.\"\n",
    "        try: movie_ids.append(int(temp_df.movieId))\n",
    "        except TypeError:\n",
    "            return \"Movie not found.\"\n",
    "    #print(movie_name)\n",
    "    result = model.predict([user, movie_ids]) + 3.7\n",
    "    string = \"User %d to below movies rating prediction is:<br>\"%(int(user[0]))\n",
    "    for i in range(len(movie_name_list)):\n",
    "        string += \"%.2f - %s<br>\"%(result[i], movie_name_list[i])\n",
    "    return string\n",
    "\n",
    "@app.route(\"/api/demo_movie\")\n",
    "def get_demo_movie():\n",
    "    out_call_df = pd.read_csv(\"/home/fio/Python/movielens_20m/Data/out_call_df.csv\")[['title', 'movieId', 'n_rating', 'genres', 'year']]\n",
    "    out_title = list(out_call_df.title)\n",
    "    out_movieId = list(out_call_df.movieId)\n",
    "    out_rate_times = list(out_call_df.n_rating)\n",
    "    out_film_year = list(out_call_df.year)\n",
    "    out_genres = []\n",
    "    for i in out_call_df.genres:\n",
    "        out_genres.append(list(i.split(\"|\")))\n",
    "    out = {\n",
    "        \"error_msg\": \"\",\n",
    "        \"title\": out_title,\n",
    "        \"movieId\": out_movieId,\n",
    "        \"rate_times\": out_rate_times,\n",
    "        \"genres\": out_genres,\n",
    "        \"film_year\": out_film_year,\n",
    "    }\n",
    "    return json.dumps(out)\n",
    " \n",
    "@app.route(\"/api/demo_user\")\n",
    "def get_demo_user():\n",
    "    out = {\n",
    "        \"error_msg\": \"\",\n",
    "        \"userId\": list(range(1,26,1)),\n",
    "    }\n",
    "    return json.dumps(out)\n",
    "    \n",
    "#啟動server\n",
    "import sys \n",
    "print(sys.version)\n",
    "if __name__ == \"__main__\":\n",
    "    serve(app, host = '0.0.0.0', port = 12348)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
